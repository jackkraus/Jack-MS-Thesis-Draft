% CHAPTER START
The Trigger/DAQ system sends and saves data from the detector to a persistent data storage solution.
The data at this stage needs to be reconstructed and consolidated into physics objects, or Analysis Object Data (AOD) files.
Creating AODs from data requires significant computation power and is undertaken by a software framework maintained by ATLAS, Athena.
This chapter will cover important tools and concepts used by ATLAS to run derivation jobs, as well as introduce data structures that represent event information. 

\section{Event Data Models} \label{sec:IO_EDM}
% \subsection{What is an Event Data Model}
An Event Data Model (EDM) is a collection of classes and their relationships to each other that provide a representation of an event detected with the goal of making it easier to use and manipulate by developers.
An EDM is how particles and jets are represented in memory, stored to disk, and manipulated in analysis.
It's useful to have an EDM because it brings a commonality to the code, aiding developers who reside in different groups often with various background experience.
An EDM allows those developers to more easily debug and communicate issues when they arise.  

\subsection{Transient/Persistent (T/P) EDM}
ATLAS used an EDM schema for Run-1 which had a separate transient and persistent status of the AOD.
AODs would often be converted to an ``ntuple" based D3DP format allowed for fast readability and partial read for efficient analysis in ROOT, though it left the files disconnected from the reconstruction tools found in Athena.\cite{Athena_xAOD_design}
When transient data was present in memory, it could have information attached to the object and gain in complexity the more it was used.
Transient data needed to be simplified before it could become persistent into long-term storage (sent to disk). 
ROOT had trouble handling the complex inheritance models that would come up the more developers used this EDM. 
Before the successor to the T/P EDM was created, ATLAS physicists would convert data samples using the full EDM to a simpler one that would be directly readable by ROOT.
This would lead to duplication of data and made it challenging to develop and maintain the analysis tools to be used on both the full EDM and the reduced ones.
Additionally, converting from transient to persistent data was an excessive step which was eventually removed by the adoption of using an EDM that blends the two stages of data together, this was dubbed the xAOD EDM.


\subsection{xAOD EDM}
The xAOD EDM is the successor to the T/P EDM and brings a number of improvements.\cite{Buckley_2015}
This EDM, unlike T/P, is usable both on Athena and ROOT.
It's easier to pick up for analysis and reconstruction. 
The xAOD EDM has the ability to add and remove variables within an \verb|ItemList| at runtime, specified in the CA script, these variables are ``decorations."

The xAOD EDM use two types of objects that handle data, interface objects and payload objects. 
Interfaces act as an interface for the user to access the object but without its stored data. 
This differs from T/P where the user wants to load an object into memory to access the object. 
If the user wanted to delay the loading of data into memory, they could use the interface object to do so. 
The payload object contains the data for the interface object and allocates contiguous blocks of memory. 
Payload classes are often referred to as auxiliary storage. 

The specific data structure used by ATLAS is the ROOT TTree, but the EDM is agnostic to the type of data structure used. 
The ROOT TTree is discussed further in the next section.
ATLAS specific libraries are not required to handle files written in the xAOD format since the payload can be read directly from the contiguous allocation of memory, a central tenent of the xAOD EDM.
This allows for the separation of ATLAS specific analysis frameworks and the preferred analysis tool of the user.
More information on how the xAOD EDM is deployed into unit tests in Section \ref{sec:Mod_utests_xAOD_object}.

\section{Athena and ROOT}
% \subsection{What is Athena}
Athena is the open-source software framework for the ATLAS experiment.\cite{athena}
It is based off the Gaudi project and uses ROOT and other software as part of the LHC Computing Grid (LCG) software stack.\cite{WLCG_Tech_design_report}
The LCG software stack is a set of software frameworks that provide general solutions for the LHC experiment's computing needs. 
It contains on the order of 500 packages, which include binary builders and compilers, language libraries and dependencies, simulation and analysis software, and more.
Athena also provides some in-house based analysis tools as well as tools for specifically ROOT based analysis.

An Athena application relies on $\textit{components}$: Algorithms, Tools, Services and Properties. \cite{Aad:2895022}  
Each component plays a role in executing an Athena application or job, where $\textsc{Python}$ is used.
ATLAS uses $\textsc{Python}$ for job configuration and steering.\footnote{Job transforms are $\textsc{Python}$ scripts that steer Athena production jobs by configuring arguments that would alter low-level behavior of the entire job. }
Specifically, an Algorithm accesses data objects in the event store, as shown with the solid lines in Figure \ref{fig:ATLAS_Athena_Job_flow}, but does not own or provide any data itself.
Algorithms can ``own" Tools, which serve as helpers exclusive to Algorithms or other components that call them.\footnote{``Ownership" here refers to the components' exclusive access or control of a Tool or Service.} 
Services are not as exclusive with its access, as they can be used by other components to provide a service such as Athena-ROOT conversion, random number generators, and others. 
Properties are able to be called at initialization of the job configuration and include flag definitions, input and output file names, and other algorithm specific options.
\verb|ComponentAccumulator| (CA) is a python class that put into Athena production as a way to prevent extra calls of setting flags during configuration. 

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{content/img/athena job.png}
  \caption{An Athena application's general structure.\cite{Aad:2895022}}
  \label{fig:ATLAS_Athena_Job_flow}
\end{figure}

An important step throughout the development of Athena is to ensure any new changes to the codebase will not overrule the functionality of core features to the present workflows.
One of the areas needed to be tested before and upon merging of any new changes to Athena is the I/O functionality, or the performance of reading and writing of stored objects within a broader context of various jobs, i.e. reconstruction or derivation.
While CA is a more general mechanism to run many kinds of job with Athena, the scope of this thesis is using CA to test core I/O functionality of the new event data model. 
An example Athena job configuration is found in Appendix \ref{app:athena-job-config}. 

ROOT is an open-source software framework used for high-energy physics analysis at CERN.\cite{ROOT_about} 
It uses C++ objects to save, access, and process data brought in by the various experiments based at the LHC, the ATLAS experiment uses it in conjunction with Athena.
ROOT largely revolves around organization and manipulation of TFiles and TTrees into ROOT files.
A TTree represents a columnar dataset, and the list of columns are called branches. 
A TTree is a ROOT object that organizes physically distinct types of event data into TBranches, or just branches.
Event data could range from information about a specific type of interaction, this includes tracks, position of particles at one point in the detector. 

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{content/img/branches_in_TTree.png}
  \caption{A snapshot of the TBranches composing a TTree, from a PHYSLITE DAOD}
  \label{fig:Branches_in_TTree}
\end{figure}

One function relevant to TTree is \verb|Fill()|. 
\verb|Fill()| will loop over all of the branches in the TTree and compresses the baskets that make up the branch.\cite{ROOT_TTree}
This initiates the data in memory to start filling a branch's basket buffer (or just ``baskets").
While this first buffer is always unoptimized, it allows opportunity to calculate an optimal basket buffer size.
At regular intervals, dictated either by number of bytes written or by number of entries written, \verb|AutoFlush| will start moving basket buffers from memory and saving them to disk. 
It's this ``flushing" mechanism that allows for easy access to the branch data as each of the baskets will be stored contiguously in memory.
The Athena default basket maximum size at present is 128 kB, and the default minimum number of entries is 10.
The minimum number of entries helps reduce processing on every entry which might be empty, and the maximum basket size is in place to prevent baskets from using too much memory throughout a Grid job.  
Prior to this thesis, the original implementation of both the basket size and minimum number of entries had not yet been fully investigated for avenues of optimization, this is explored in Section \ref{sec:DAODProd_Analysis}.

% % CMake
CMake and Make are open-source software that is used to build Athena, ROOT, and other software.
A sparse build is a way to make changes to an individual package of code without having to recompile the entire framework at once, which saves time and resources. 
A user can create a text file identifying the path to the package modified, and the sparse build for Athena will proceed upon issuing the following commands:
\begin{lstlisting}[language=bash]
    cmake -DATLAS_PACKAGE_FILTER_FILE=../package_filters.txt ../athena/Projects/WorkDir/ 
    make -j
\end{lstlisting}

% How we used it
% % Athena POOL
The POOL framework is part of a larger framework known as the Persistency Framework (PF). \cite{Trentadue_2012}
The PF was developed with the intent to be independent of any individual experiment, and the goal was to address data access requirements of LHC experiments in different ways.
POOL was in charge of C++ object storage, collection of metadata, and file catalogs by using streaming and relational technologies. 
POOL provided highly scalable object serialization to framework evolving PF files. 
It was eventually discontinued by other experiments in favor of a newer persistency mechanism that uses ROOT in a more streamlined way.
ATLAS then became the sole supporter of POOL and integrated it within Athena to support persistent navigation of the ROOT storage layer.
Now, Athena has both the original PF POOL functionality and a separate modern AthenaPool functionality. 
AthenaPool resides in the ATLAS I/O framework and controls ROOT TTree and TBranch properties such as compression and basket buffer sizing.

% What we looked at/How we used it

\subsection{Continuous Integration (CI) and Development}
CI is a software development practice where new code is tested and validated upon each merge to the main branch of a repository. 
Every commit to the main branch is automatically built and tested for specific core features that are required to work with the codebase. 
This helps to ensure that the codebase is working as intended and that any new code is compatible with the existing codebase.

Athena is hosted on GitLab and developed using CI with an instance of Jenkins, called ATLAS Robot, which builds and tests the new changes within a merge request interface.\cite{athena-gitlab}\cite{Jenkins}
ATLAS Robot will then provide a report of the build and test results.
If the build or test fail, ATLAS Robot will provide a report of which steps failed and why.
This allows for early detection of issues before the nightly build is compiled and tested.


\section{Derivation Production Jobs}
 \label{section: ATLASIO_Derivation}

A derivation production job takes AODs, which comes from the reconstruction step at $\mathcal{O}(1 \text{ MB})$ per event, and creates a derived AOD (DAOD) which sits at $\mathcal{O}(10 \text{ kB})$ per event.
Derivation production is a necessary step to make all data accessible for physicists doing analysis as well as reducing the amount of data that needs to be processed.
While derivations are reduced AODs, they often contain additional information useful for analysis, such as jet collections and high-level discriminants.\cite{PHYSLITE_A_new_2024}
The two mainstream output file formats Athena is capable of handling are PHYS and PHYSLITE.  
Figure \ref{fig:IO_tt_PHYS_vs_PHYSLITE} shows the object composition of a PHYS and PHYSLITE $t\bar{t}$ sample. 

% TODO: How does MC differ from Data in terms of composition? 
\begin{figure}[h]
    \centering
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{content/img/tt_PHYS.png}
        % \caption{A subfigure}
        \label{fig:IO_tt_PHYS_subA}
      \end{subfigure}%     
      \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{content/img/tt_PHYSLITE.png}
        % \caption{B subfigure}
        \label{fig:IO_tt_PHYSLITE_subB}
      \end{subfigure}% 
    \caption{Object composition of a PHYS and PHYSLITE $t\bar{t}$ MC simulated sample from Run 3.}
    \label{fig:IO_tt_PHYS_vs_PHYSLITE}
\end{figure}
PHYS output files, at 40.0 kB per event, is predominantly made of jet collections, while PHYSLITE, at 16.1 kB per event, has more trigger and track information.
PHYSLITE, being the smaller file of the two, had a higher concentration of 
% Is it true that PHYSLITE compresses more?  

These jobs can demand heavy resource usage on the GRID, so optimization of the AOD/DAODs for derivation jobs can be vital. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{content/img/catmore-derivation.png}
    \caption{Derivation production from Reconstruction to Final N-Tuple\cite{DAOD_Laycock_2014}}
    \label{fig:IO_derivation_framework}
\end{figure}

The derivation framework is sequence of steps that are performed on the AODs to create the DAODs.
Skimming is the first step in the derivation framework, and is responsible for removing whole events based on pre-defined criteria.
Thinning is the second step, and it removes whole objects based on pre-defined criteria.
Lastly slimming removes variables from objects uniformly across events. 



